[2024-11-13 21:05:16 root] (main_block_ap.py 122): INFO Namespace(model=None, cache_dir='./cache', output_dir='./output/inference_results/', save_quant_dir=None, real_quant=False, resume_quant='./output/pre_quantized_models/Llama-2-7b-EfficientQAT-w2g64', calib_dataset='redpajama', train_size=4096, val_size=64, training_seqlen=2048, batch_size=2, epochs=2, ppl_seqlen=128, seed=2, eval_ppl=True, eval_tasks='', eval_batch_size=8, wbits=2, group_size=64, quant_lr=0.0001, weight_lr=1e-05, min_lr_factor=20, clip_grad=0.3, wd=0, net='Llama-2', max_memory='70GiB', early_stop=0, off_load_to_disk=False)
[2024-11-13 21:05:16 root] (main_block_ap.py 127): INFO Using device: cuda
[2024-11-13 21:05:21 root] (main_block_ap.py 166): INFO Memory footprint after loading quantized model: 2.28GiB
